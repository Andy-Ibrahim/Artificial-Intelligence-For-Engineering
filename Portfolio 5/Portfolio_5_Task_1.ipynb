{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ugsHhjnBUy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ff6254-a95f-4717-ca91-98f1034bccd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define base path and folder paths\n",
        "base_path = '/content/drive/My Drive/Colab Notebooks'\n",
        "\n",
        "# Corrected folder paths\n",
        "no_rust_train_path = os.path.join(base_path, 'Corrosion_Train', 'no rust')\n",
        "rust_train_path = os.path.join(base_path, 'Corrosion_Train', 'rust')\n",
        "no_rust_test_path = os.path.join(base_path, 'No Rust_Test')\n",
        "rust_test_path = os.path.join(base_path, 'Rust_Test')"
      ],
      "metadata": {
        "id": "kpKoFp5WOA8S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "# Function to load images from a directory\n",
        "def load_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    for filename in glob.glob(os.path.join(folder_path, '*')):\n",
        "        # Check if it's a file (not a directory) and has an image extension\n",
        "        if os.path.isfile(filename) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            try:\n",
        "                img = Image.open(filename)\n",
        "                images.append(img)\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load image {filename}: {e}\")\n",
        "    return images\n",
        "\n",
        "\n",
        "# Load images from each folder\n",
        "no_rust_train_images = load_images_from_folder(no_rust_train_path)\n",
        "rust_train_images = load_images_from_folder(rust_train_path)\n",
        "no_rust_test_images = load_images_from_folder(no_rust_test_path)\n",
        "rust_test_images = load_images_from_folder(rust_test_path)\n",
        "\n",
        "\n",
        "# Print the number of images loaded from each folder\n",
        "print(f\"Number of images in no rust train: {len(no_rust_train_images)}\")\n",
        "print(f\"Number of images in rust train: {len(rust_train_images)}\")\n",
        "print(f\"Number of images in No Rust Test: {len(no_rust_test_images)}\")\n",
        "print(f\"Number of images in Rust Test: {len(rust_test_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U808q-6hQAQK",
        "outputId": "93affc9d-e56e-4b09-a40c-a7d7abb7dbba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in no rust train: 405\n",
            "Number of images in rust train: 345\n",
            "Number of images in No Rust Test: 10\n",
            "Number of images in Rust Test: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def preprocess_images(images, target_size):\n",
        "    processed_images = []\n",
        "    for img in images:\n",
        "        if isinstance(img, np.ndarray):\n",
        "            # Convert numpy array to uint8 if necessary\n",
        "            img = img.astype(np.uint8)\n",
        "\n",
        "            # Resize using OpenCV\n",
        "            img = cv2.resize(img, target_size)\n",
        "        else:\n",
        "            # Ensure the image is in RGB format\n",
        "            img = img.convert('RGB')\n",
        "            img = img.resize(target_size)  # Resize image to target size\n",
        "\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "        processed_images.append(img_array)\n",
        "\n",
        "    return np.array(processed_images)\n",
        "\n",
        "\n",
        "\n",
        "# Define target image size and preprocess images\n",
        "target_size = (128, 128)  # Adjust to your image size\n",
        "no_rust_train_images = preprocess_images(no_rust_train_images, target_size)\n",
        "rust_train_images = preprocess_images(rust_train_images, target_size)\n",
        "\n",
        "# Combine the images and create labels\n",
        "X_train = np.concatenate([no_rust_train_images, rust_train_images], axis=0)\n",
        "y_train = np.concatenate([np.zeros(len(no_rust_train_images)), np.ones(len(rust_train_images))], axis=0)\n",
        "\n",
        "# Convert labels to categorical format\n",
        "y_train = to_categorical(y_train, num_classes=2)\n"
      ],
      "metadata": {
        "id": "HaNB6GhwUoWs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Define the variables\n",
        "num_filters = 32  # Number of filters in the Conv2D layer\n",
        "filter_size = (3, 3)  # Size of the filter/kernel\n",
        "pool_size = (2, 2)  # Size of the pooling window\n",
        "\n",
        "# Define CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(num_filters, filter_size, activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # 2 classes (rust and no rust)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDlHN9mSXGUY",
        "outputId": "75f7ad39-a75c-46c9-fd38-de3af2eba47a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_u8KbJKXIpt",
        "outputId": "8bd5c1e1-0c3e-4656-ec66-6ef95ff2f35a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 655ms/step - accuracy: 0.6437 - loss: 4.1219 - val_accuracy: 0.1200 - val_loss: 1.5149\n",
            "Epoch 2/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 553ms/step - accuracy: 0.6568 - loss: 0.6305 - val_accuracy: 0.6467 - val_loss: 0.7245\n",
            "Epoch 3/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 430ms/step - accuracy: 0.7686 - loss: 0.4849 - val_accuracy: 0.5400 - val_loss: 0.8571\n",
            "Epoch 4/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 524ms/step - accuracy: 0.8296 - loss: 0.4006 - val_accuracy: 0.4800 - val_loss: 0.9485\n",
            "Epoch 5/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 584ms/step - accuracy: 0.8273 - loss: 0.3737 - val_accuracy: 0.4600 - val_loss: 0.9883\n",
            "Epoch 6/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 513ms/step - accuracy: 0.8855 - loss: 0.3266 - val_accuracy: 0.6533 - val_loss: 0.7762\n",
            "Epoch 7/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 552ms/step - accuracy: 0.8929 - loss: 0.2733 - val_accuracy: 0.7133 - val_loss: 0.5385\n",
            "Epoch 8/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 604ms/step - accuracy: 0.9237 - loss: 0.2269 - val_accuracy: 0.8133 - val_loss: 0.3670\n",
            "Epoch 9/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 449ms/step - accuracy: 0.9246 - loss: 0.2259 - val_accuracy: 0.8200 - val_loss: 0.3212\n",
            "Epoch 10/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 451ms/step - accuracy: 0.9407 - loss: 0.2241 - val_accuracy: 0.7667 - val_loss: 0.4877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fdae438f730>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess test images\n",
        "no_rust_test_images = preprocess_images(no_rust_test_images, target_size)\n",
        "rust_test_images = preprocess_images(rust_test_images, target_size)\n",
        "\n",
        "# Combine test images and create labels\n",
        "X_test = np.concatenate([no_rust_test_images, rust_test_images], axis=0)\n",
        "y_test = np.concatenate([np.zeros(len(no_rust_test_images)), np.ones(len(rust_test_images))], axis=0)\n",
        "y_test = to_categorical(y_test, num_classes=2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QXRx9osXSFJ",
        "outputId": "5051a677-37dc-47ce-b1f9-4764de037a80"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9500 - loss: 0.2870\n",
            "Test accuracy: 95.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restnet50"
      ],
      "metadata": {
        "id": "cPZVXw8eej8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Define the base model with ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Add custom layers on top of ResNet50\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)  # Add dropout for regularization\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)  # 2 classes (rust and no rust)\n",
        "\n",
        "# Define the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers of the base model (ResNet50)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # Use 20% of data for validation\n",
        ")\n",
        "\n",
        "# Train the model using data augmentation\n",
        "batch_size = 16\n",
        "epochs = 10\n",
        "\n",
        "train_generator = datagen.flow(X_train, y_train, batch_size=batch_size, subset='training')\n",
        "validation_generator = datagen.flow(X_train, y_train, batch_size=batch_size, subset='validation')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI-bAYkI_AWR",
        "outputId": "1efd4a49-c165-4473-d0e5-20e98168bc31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy with ResNet50: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "aTyHTBQX_ejg",
        "outputId": "0f568975-2b3f-4713-f123-062a52ef954e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - accuracy: 0.5304 - loss: 0.6966 - val_accuracy: 0.0000e+00 - val_loss: 0.7587\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'items'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-73139e0cd5e4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 )\n\u001b[1;32m    353\u001b[0m                 val_logs = {\n\u001b[0;32m--> 354\u001b[0;31m                     \u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m                 }\n\u001b[1;32m    356\u001b[0m                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ]
    }
  ]
}